# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15ooqobmPKKEvYu9lwe662Ekema3iOfuA
"""

# General imports
import numpy as np
import matplotlib.pyplot as plt
from sklearn.utils import shuffle
from sklearn.model_selection import GridSearchCV
import os
import sys
import pandas as pd
from google.colab import drive
# Keras
import keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

drive.mount("/content/drive", force_remount=True)


### Already implemented
def get_data(datafile):
	dataframe = pd.read_csv(datafile)
	dataframe = shuffle(dataframe)
	data = list(dataframe.values)
	labels, images = [], []
	for line in data:
		labels.append(line[0])
		images.append(line[1:])
	labels = np.array(labels)
	images = np.array(images).astype('float32')
	images /= 255
	return images, labels
def get_test_data(datafile):
	dataframe = pd.read_csv(datafile)
	data = list(dataframe.values)
	labels, images = [], []
	for line in data:
		labels.append(line[0])
		images.append(line[1:])
	labels = np.array(labels)
	images = np.array(images).astype('float32')
	images /= 255
	return images, labels

### Already implemented
def visualize_weights(trained_model, num_to_display=8, save=False, hot=True):
	layer1 = trained_model.layers[0]
	weights = layer1.get_weights()[0]

	# Feel free to change the color scheme
	colors = 'hot' if hot else 'binary'
	try:
		os.mkdir('weight_visualizations')
	except FileExistsError:
		pass
	for i in range(num_to_display):
		wi = weights[:,i].reshape(28, 28)
		plt.imshow(wi, cmap=colors, interpolation='nearest')
		if save:
			plt.savefig('./weight_visualizations/unit' + str(i) + '_weights.png')
		else:
			plt.show()


### Already implemented
def output_predictions(predictions):
	with open('predictions.txt', 'w+') as f:
		for pred in predictions:
			f.write(str(pred) + '\n')


def plot_history(history):
  train_loss_history = history.history['loss']
  val_loss_history = history.history['val_loss']

  train_acc_history = history.history['acc']
  val_acc_history = history.history['val_acc']

  


def create_mlp(args=None):
  # You can use args to pass parameter values to this method
  # Define model architecture
  model = Sequential()
  #784 pixels
  model.add(Dense(units=56, activation='relu', input_dim=28*28))
  model.add(Dense(units=128, activation='relu'))
  model.add(Dense(units=10, activation='softmax'))
	# add more layers...

	# Define Optimizer
  
  optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)

	# Compile
  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
  return model

def train_mlp(x_train, y_train, x_vali=None, y_vali=None, args=None):
	# You can use args to pass parameter values to this method
  y_train = keras.utils.to_categorical(y_train, num_classes=None)
  model = create_mlp(args)
  history = model.fit(x_train, y_train, epochs=6, batch_size=8, validation_split=0)
  return model, history


def create_cnn(args=None):
	# You can use args to pass parameter values to this method

	# 28x28 images with 1 color channel
  input_shape = (28, 28, 1)

	# Define model architecture
  model=Sequential()
  model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),activation='relu',input_shape=input_shape))
  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
  
  model.add(Flatten())
  model.add(Dropout(.5))
  model.add(Dense(1000, activation='relu'))
  model.add(Dropout(.5))
  model.add(Dense(10, activation='softmax'))
	# Optimizer
  optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None)
	# Compile
  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
  print("layer output: ",model.layers[0].get_config())
  return model


def train_cnn(x_train, y_train, x_vali=None, y_vali=None, args=None):
	# You can use args to pass parameter values to this method
  x_train = x_train.reshape(-1, 28, 28, 1)
  y_train = keras.utils.to_categorical(y_train, num_classes=None)
  model = create_cnn(args)
  history = model.fit(x_train, y_train, epochs=7, batch_size=16, validation_split=.15)
  return model, history

def train_and_select_model(train_csv):
	"""Optional method. You can write code here to perform a 
	parameter search, cross-validation, etc. """

	x_train, y_train = get_data(train_csv)

	args = {
		'learning_rate': 0.1,
	}
	smodel, history = train_cnn(x_train, y_train, x_vali=None, y_vali=None, args=None)
  #smodel, history = train_cnn(x_train, y_train, x_vali=None, y_vali=None, args=None)
	#validation_accuracy = history.history['val_acc']
	
	return smodel, history
def plot_data(history):
  plt.plot(history.history['acc'])
  plt.plot(history.history['val_acc'])
  plt.title('model accuracy')
  plt.ylabel('accuracy')
  plt.xlabel('epoch')
  plt.legend(['train', 'test'], loc='upper left')
  plt.xmin=1
  plt.show()
  # summarize history for loss
  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  plt.title('model loss')
  plt.ylabel('loss')
  plt.xlabel('epoch')
  plt.legend(['train', 'test'], loc='upper left')
  plt.xmin=1
  plt.show()

if __name__ == '__main__':
  ### Before you submit, switch this to grading_mode = False and rerun ###
  grading_mode = False
  if grading_mode:
    # When we grade, we'll provide the file names as command-line arguments
    if (len(sys.argv) != 3):
      print("Usage:\n\tpython3 fashion.py train_file test_file")
      exit()
    train_file, test_file = sys.argv[1], sys.argv[2]
    cnn_model, cnn_history = train_and_select_model(train_file)
    Outfile=open("predictions.txt","a+")
    image, label = get_data(test_file)
    #image=image.reshape(-748, 28, 28, 1)
    for x in range(0,10000):
      #print(image[x])
      stuff=(cnn_model.predict_classes(image[x].reshape(-1, 28, 28, 1)))
      print("PREDICTIONS:",stuff,x)
      Outfile.write(str(stuff))
    Outfile.close()
		# train your best model
		#best_model = train_and_select_model(test_file)
		
		# use your best model to generate predictions for the test_file
    #predictions = []
    #output_predictions(predictions)

		# Include all of the required figures in your report. Don't generate them here.

  else:
    train_file = '/content/drive/My Drive/NNets/fashion_train.csv'
    test_file = '/content/drive/My Drive/NNets/fashion_test.csv'
		# MLP
    #mlp_model, mlp_history = train_and_select_model(train_file)
    #plot_history(mlp_history)
    #visualize_weights(mlp_model)
    #plot_data(mlp_history)
    #print(mlp_model.summary())
    
    
    
		# CNN
    cnn_model, cnn_history = train_and_select_model(train_file)
    Outfile=open("predictions.txt","a+")
    image, label = get_test_data(test_file)
    #image=image.reshape(-748, 28, 28, 1)
    for x in range(0,10000):
      #print(image[x])
      stuff=(cnn_model.predict_classes(image[x].reshape(-1, 28, 28, 1)))
      print(stuff)
      Outfile.write(str(stuff))
    Outfile.close()
    plot_history(cnn_history)  
    print(cnn_model.summary())
    plot_data(cnn_history)
